[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Ampere" with compute capability 8.0

MatrixA(16384,16384), MatrixB(16384,16384)
Computing result using CUDA Kernel...
done
Performance= 5410.42 GFlop/s, Time= 1625.770 msec, Size= 8796093022208 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cuda_fp32_16384x16384x16384_nvml_log.csv
Executing command: ../src/gemm/gemm_naive_float -wA=16384 -hA=16384 -wB=16384 -hB=16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([16384, 16384])
Matrix B: torch.Size([16384, 16384])
Time taken for 1000 iterations: 466371.5345 ms
Time taken for one iteration: 466.3715 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp32_16384x16384x16384_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp32 --gpu 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 460857ms for 1000 iterations (460.857ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp32_cc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 472369ms for 1000 iterations (472.369ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp32_cc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 228818ms for 1000 iterations (228.818ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_cc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 250847ms for 1000 iterations (250.847ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_cc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([16384, 16384])
Matrix B: torch.Size([16384, 16384])
Time taken for 1000 iterations: 34182.9689 ms
Time taken for one iteration: 34.1830 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp16_16384x16384x16384_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp16 --gpu 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 29073.1ms for 1000 iterations (29.0731ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_tc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 55196.7ms for 1000 iterations (55.1967ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_tc_16384x16384x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 16384 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
