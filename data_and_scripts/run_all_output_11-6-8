[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Ampere" with compute capability 8.0

MatrixA(4096,4096), MatrixB(4096,4096)
Computing result using CUDA Kernel...
done
Performance= 5347.60 GFlop/s, Time= 25.701 msec, Size= 137438953472 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cuda_fp32_4096x4096x4096_nvml_log.csv
Executing command: ../src/gemm/gemm_naive_float -wA=4096 -hA=4096 -wB=4096 -hB=4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Ampere" with compute capability 8.0

MatrixA(4096,16384), MatrixB(32,4096)
Computing result using CUDA Kernel...
done
Performance= 4858.94 GFlop/s, Time= 0.884 msec, Size= 4294967296 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cuda_fp32_16384x32x4096_nvml_log.csv
Executing command: ../src/gemm/gemm_naive_float -wA=4096 -hA=16384 -wB=32 -hB=4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Ampere" with compute capability 8.0

MatrixA(4096,32), MatrixB(16384,4096)
Computing result using CUDA Kernel...
done
Performance= 4833.19 GFlop/s, Time= 0.889 msec, Size= 4294967296 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cuda_fp32_32x16384x4096_nvml_log.csv
Executing command: ../src/gemm/gemm_naive_float -wA=4096 -hA=32 -wB=16384 -hB=4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Ampere" with compute capability 8.0

MatrixA(16384,1024), MatrixB(4096,16384)
Computing result using CUDA Kernel...
done
Performance= 5331.05 GFlop/s, Time= 25.781 msec, Size= 137438953472 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cuda_fp32_1024x4096x16384_nvml_log.csv
Executing command: ../src/gemm/gemm_naive_float -wA=16384 -hA=1024 -wB=4096 -hB=16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([4096, 4096])
Matrix B: torch.Size([4096, 4096])
Time taken for 1000 iterations: 7355.1598 ms
Time taken for one iteration: 7.3552 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp32_4096x4096x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp32 --gpu 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([16384, 32])
Matrix B: torch.Size([32, 4096])
Time taken for 1000 iterations: 307.5930 ms
Time taken for one iteration: 0.3076 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp32_16384x32x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp32 --gpu 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([32, 16384])
Matrix B: torch.Size([16384, 4096])
Time taken for 1000 iterations: 309.5537 ms
Time taken for one iteration: 0.3096 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp32_32x16384x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp32 --gpu 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([1024, 4096])
Matrix B: torch.Size([4096, 16384])
Time taken for 1000 iterations: 7342.4355 ms
Time taken for one iteration: 7.3424 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp32_1024x4096x16384_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp32 --gpu 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 7274.43ms for 1000 iterations (7.27443ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp32_cc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 309.02ms for 1000 iterations (0.30902ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp32_cc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 369.699ms for 1000 iterations (0.369699ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp32_cc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 7609.19ms for 1000 iterations (7.60919ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp32_cc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 7803.68ms for 1000 iterations (7.80368ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp32_cc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 1582.33ms for 1000 iterations (1.58233ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp32_cc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 1581.89ms for 1000 iterations (1.58189ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp32_cc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 9404.81ms for 1000 iterations (9.40481ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp32_cc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp32 --accprecision fp32 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 3869.73ms for 1000 iterations (3.86973ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_cc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 331.709ms for 1000 iterations (0.331709ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_cc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 531.986ms for 1000 iterations (0.531986ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_cc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 3729.54ms for 1000 iterations (3.72954ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_cc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 4202.37ms for 1000 iterations (4.20237ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_cc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 894.736ms for 1000 iterations (0.894736ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_cc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 887.334ms for 1000 iterations (0.887334ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_cc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 5190.55ms for 1000 iterations (5.19055ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_cc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --cudacoresonly --mulprecision fp16 --accprecision fp16 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([4096, 4096])
Matrix B: torch.Size([4096, 4096])
Time taken for 1000 iterations: 595.6349 ms
Time taken for one iteration: 0.5956 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp16_4096x4096x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp16 --gpu 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([16384, 32])
Matrix B: torch.Size([32, 4096])
Time taken for 1000 iterations: 134.0641 ms
Time taken for one iteration: 0.1341 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp16_16384x32x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp16 --gpu 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([32, 16384])
Matrix B: torch.Size([16384, 4096])
Time taken for 1000 iterations: 109.6774 ms
Time taken for one iteration: 0.1097 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp16_32x16384x4096_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp16 --gpu 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
Device: cuda
Number of iterations: 1000
Matrix A: torch.Size([1024, 4096])
Matrix B: torch.Size([4096, 16384])
Time taken for 1000 iterations: 580.4428 ms
Time taken for one iteration: 0.5804 ms
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_torch_fp16_1024x4096x16384_nvml_log.csv
Executing command: python3 ../src/gemm/gemm_torch.py -i 1000 -p fp16 --gpu 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 553.389ms for 1000 iterations (0.553389ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_tc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --mulprecision fp16 --accprecision fp16 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 158.764ms for 1000 iterations (0.158764ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_tc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 163.219ms for 1000 iterations (0.163219ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_tc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --mulprecision fp16 --accprecision fp16 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUBLAS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 560.146ms for 1000 iterations (0.560146ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cublas_fp16_tc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --usecublas --mulprecision fp16 --accprecision fp16 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 530.493ms for 1000 iterations (0.530493ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_tc_4096x4096x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --mulprecision fp16 --accprecision fp16 --iterations 1000 4096 4096 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 138.824ms for 1000 iterations (0.138824ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_tc_16384x32x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --mulprecision fp16 --accprecision fp16 --iterations 1000 16384 32 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 138.495ms for 1000 iterations (0.138495ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_tc_32x16384x4096_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --mulprecision fp16 --accprecision fp16 --iterations 1000 32 16384 4096
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
[INFO] CUDA Bench - General Matrix-Matrix Multiplication (GEMM) 
[INFO] Version 1.0.0 (C)2022 Bagus Hanindhito 
[INFO] Matrix-Matrix multiplication follows equation: C = (alpha)x(AxB) + (beta)xC
[INFO] where alpha=1.00, beta=0.00, and A[MxK], B[KxN], and C[MxN] are matrices 


[INFO] Program is using NVIDIA CUTLASS library for GEMM
[INFO] Detected 1 CUDA-capable device(s)
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |#  |Device Name             |CC  |#SM |Freq. (MHz)|Mem. Size (MB)|Mem. BW (GB/s)|
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[INFO] |0  |NVIDIA A100-SXM4-40GB   |8.0 |108 |1410       |40626         |1555.2        |
[INFO] +---+------------------------+----+----+-----------+--------------+--------------+
[WARN] This program does not currently support Multi-GPU run.
[INFO] Execution Time: 604.52ms for 1000 iterations (0.60452ms/iteration)
GPU monitoring started with interval 1.00 ms
Results will be saved to: logs/gemm_cutlass_fp16_tc_1024x4096x16384_nvml_log.csv
Executing command: ../bin/gemm_cuda_bench --mulprecision fp16 --accprecision fp16 --iterations 1000 1024 4096 16384
Monitoring GPU: NVIDIA A100-SXM4-40GB
Command completed with return code: 0
Waiting for monitoring thread to finish...
Monitoring thread exiting
Cleaning up resources...
Monitoring finished
